"""
üî• EXPERIMENTO FINAL AGRESIVO - SOVEREIGNTY MONITOR üî•
¬øPuede L predecir el colapso ANTES del overfitting extremo?

Modelo grande + entrenamiento agresivo para forzar colapso real
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List
import warnings
import time

# Configurar matplotlib
def setup_matplotlib_for_plotting():
    warnings.filterwarnings('default')
    plt.switch_backend("Agg")
    plt.style.use("seaborn-v0_8")
    plt.rcParams["font.sans-serif"] = ["Noto Sans CJK SC", "WenQuanYi Zen Hei", "PingFang SC", "Arial Unicode MS", "Hiragino Sans GB"]
    plt.rcParams["axes.unicode_minus"] = False

class SovereigntyMonitor:
    """Implementaci√≥n del Sovereignty Monitor basada en RESMA"""
    def __init__(self, epsilon_c: float = 0.1):
        self.epsilon_c = epsilon_c
        
    def calcular_libertad(self, weights: torch.Tensor) -> Tuple[float, float, int]:
        """Calcula la m√©trica L (libertad) de una matriz de pesos"""
        try:
            W = weights.detach().cpu().numpy()
            U, S, Vh = np.linalg.svd(W, full_matrices=False)
            
            # Rango efectivo
            threshold = 0.01 * np.max(S)
            if threshold == 0:
                threshold = 1e-10
            rank_effective = max(1, np.sum(S > threshold))
            
            # Entrop√≠a de von Neumann
            S_sum = np.sum(S)
            if S_sum == 0:
                S_sum = 1e-10
            S_normalized = S / S_sum
            S_normalized = S_normalized[S_normalized > 1e-15]
            if len(S_normalized) == 0:
                S_normalized = np.array([1.0])
            S_vn = -np.sum(S_normalized * np.log(S_normalized))
            
            # M√©trica L
            log_rank = np.log(rank_effective + 1)
            denominador = np.abs(S_vn - log_rank) + self.epsilon_c
            L = 1.0 / denominador
            
            return L, S_vn, rank_effective
            
        except Exception as e:
            return 1.0, 0.0, 1  # Valores por defecto
    
    def evaluar_regimen(self, L: float) -> str:
        """Eval√∫a el r√©gimen del modelo"""
        if L > 1.0:
            return "SOBERANO"
        elif L > 0.5:
            return "EMERGENTE" 
        else:
            return "ESPURIO"

class ModeloGrande(nn.Module):
    """Modelo grande dise√±ado para colapsar con entrenamiento extremo"""
    def __init__(self):
        super().__init__()
        # M√∫ltiples capas grandes para inducir colapso
        self.fc1 = nn.Linear(784, 1024)   # Muy grande
        self.fc2 = nn.Linear(1024, 512)   # Muy grande
        self.fc3 = nn.Linear(512, 256)    # Grande
        self.fc4 = nn.Linear(256, 128)    # Grande
        self.fc5 = nn.Linear(128, 10)     # Salida
        
        self.dropout = nn.Dropout(0.0)    # Sin dropout para forzar overfitting
        self.batch_norm1 = nn.BatchNorm1d(1024)
        self.batch_norm2 = nn.BatchNorm1d(512)
        self.batch_norm3 = nn.BatchNorm1d(256)
        
    def forward(self, x):
        x = x.view(-1, 784)
        x = F.relu(self.batch_norm1(self.fc1(x)))
        x = self.dropout(x)
        x = F.relu(self.batch_norm2(self.fc2(x)))
        x = self.dropout(x)
        x = F.relu(self.batch_norm3(self.fc3(x)))
        x = self.dropout(x)
        x = F.relu(self.fc4(x))
        x = self.fc5(x)
        return x
    
    def get_linear_layers(self):
        return [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5]

def generar_datos_toxico():
    """Genera datos dise√±ados espec√≠ficamente para causar colapso"""
    print("üíÄ Generando datos T√ìXICOS para forzar colapso...")
    
    np.random.seed(42)
    torch.manual_seed(42)
    
    # Datos muy peque√±os con mucho ruido
    n_samples = 50  # Extremadamente peque√±o
    n_features = 784  # MNIST flattened
    
    # Datos aleatorios sin estructura (imposible de aprender)
    train_imgs = torch.randn(n_samples, n_features) * 0.1  # Muy peque√±o
    train_labels = torch.randint(0, 10, (n_samples,))
    
    val_imgs = torch.randn(20, n_features) * 0.1  # A√∫n m√°s peque√±o
    val_labels = torch.randint(0, 10, (20,))
    
    print(f"   ‚ö†Ô∏è  Dataset T√ìXICO: {n_samples} train, {val_imgs.shape[0]} val")
    print(f"   üéØ Objetivo: Forzar overfitting extremo")
    
    return (train_imgs, train_labels), (val_imgs, val_labels)

def experimento_colapso_forzado():
    """Experimento dise√±ado para forzar el colapso del modelo"""
    print("\nüöÄ INICIANDO EXPERIMENTO DE COLAPSO FORZADO")
    print("="*70)
    print("üéØ ¬øPuede L predecir el colapso en condiciones EXTREMAS?")
    print("üíÄ Modelo grande + datos t√≥xicos + entrenamiento agresivo")
    print()
    
    inicio = time.time()
    
    # Configuraci√≥n AGRESIVA
    device = torch.device('cpu')
    monitor = SovereigntyMonitor()
    modelo = ModeloGrande().to(device)
    
    # Par√°metros de colapso forzado
    optimizer = optim.SGD(modelo.parameters(), lr=0.1)  # LR muy alto
    criterion = nn.CrossEntropyLoss()
    
    # Datos t√≥xicos
    (train_imgs, train_labels), (val_imgs, val_labels) = generar_datos_toxico()
    
    # Historial detallado
    historial = {
        'epoca': [],
        'loss_train': [],
        'loss_val': [],
        'L_promedio': [],
        'L_fc1': [],
        'L_fc2': [],
        'L_fc3': [],
        'L_fc4': [],
        'L_fc5': [],
        'regimen': [],
        'entropia': []
    }
    
    print(f"üì± Dispositivo: {device}")
    print("üíÄ 30 √©pocas de entrenamiento EXTREMO")
    print("üî• Learning rate: 0.1 (EXTREMADAMENTE alto)")
    print("üóëÔ∏è  Dropout: 0.0 (sin protecci√≥n)")
    print("-"*70)
    
    # Entrenamiento COLAPSO FORZADO
    for epoca in range(30):
        # === ENTRENAMIENTO AGRESIVO ===
        modelo.train()
        
        # M√∫ltiples pasos por √©poca para acelerar colapso
        for _ in range(5):  # 5 pasos por √©poca
            optimizer.zero_grad()
            outputs = modelo(train_imgs)
            loss = criterion(outputs, train_labels)
            loss.backward()
            
            # Gradient clipping para evitar NaN pero mantener presi√≥n
            torch.nn.utils.clip_grad_norm_(modelo.parameters(), max_norm=1.0)
            
            optimizer.step()
        
        train_loss = loss.item()
        
        # === EVALUACI√ìN ===
        modelo.eval()
        with torch.no_grad():
            val_outputs = modelo(val_imgs)
            val_loss = criterion(val_outputs, val_labels).item()
        
        # === MONITOREO L DETALLADO ===
        L_vals = []
        S_vn_vals = []
        layers = modelo.get_linear_layers()
        
        for i, layer in enumerate(layers):
            L, S_vn, rank = monitor.calcular_libertad(layer.weight)
            L_vals.append(L)
            S_vn_vals.append(S_vn)
            
            # Guardar L individual por capa
            if i == 0:
                historial['L_fc1'].append(L)
            elif i == 1:
                historial['L_fc2'].append(L)
            elif i == 2:
                historial['L_fc3'].append(L)
            elif i == 3:
                historial['L_fc4'].append(L)
            elif i == 4:
                historial['L_fc5'].append(L)
        
        L_promedio = np.mean(L_vals)
        S_vn_promedio = np.mean(S_vn_vals)
        regimen = monitor.evaluar_regimen(L_promedio)
        
        # Guardar m√©tricas
        historial['epoca'].append(epoca)
        historial['loss_train'].append(train_loss)
        historial['loss_val'].append(val_loss)
        historial['L_promedio'].append(L_promedio)
        historial['regimen'].append(regimen)
        historial['entropia'].append(S_vn_promedio)
        
        # Reporte cada √©poca para ver el colapso en tiempo real
        if epoca % 2 == 0 or epoca == 29:
            print(f"Ep {epoca:2d} | "
                  f"Train: {train_loss:.4f} | "
                  f"Val: {val_loss:.4f} | "
                  f"L: {L_promedio:.3f} ({regimen})")
    
    tiempo_total = time.time() - inicio
    print("-"*70)
    print(f"‚è±Ô∏è  Entrenamiento completado en {tiempo_total:.1f} segundos")
    print("üíÄ AN√ÅLISIS DE COLAPSO EXTREMO")
    print("="*70)
    
    # === DETECCI√ìN DE COLAPSO ===
    colapso_epoca = None
    for i, L in enumerate(historial['L_promedio']):
        if L < 0.5:
            colapso_epoca = historial['epoca'][i]
            break
    
    # Detectar deterioro gradual de L
    deterioro_epoca = None
    L_inicial = historial['L_promedio'][0]
    for i in range(1, len(historial['L_promedio'])):
        L_actual = historial['L_promedio'][i]
        if L_actual < L_inicial * 0.5:  # L baj√≥ 50% del inicial
            deterioro_epoca = historial['epoca'][i]
            break
    
    # === VERIFICAR PODER PREDICTIVO ===
    if colapso_epoca is not None:
        print(f"üö® COLAPSO SEVERO detectado en √©poca {colapso_epoca}")
        print(f"   L = {historial['L_promedio'][colapso_epoca]:.3f} < 0.5")
        print(f"   R√©gimen cambi√≥ a: {historial['regimen'][colapso_epoca]}")
    else:
        print("‚úÖ No se detect√≥ colapso severo (L > 0.5)")
    
    if deterioro_epoca is not None:
        print(f"üìâ DETERIORO GRADUAL detectado en √©poca {deterioro_epoca}")
        print(f"   L baj√≥ 50% desde el valor inicial")
    
    # An√°lisis del comportamiento de L
    L_final = historial['L_promedio'][-1]
    L_cambio = ((L_final - L_inicial) / L_inicial) * 100
    
    print(f"\nüìä AN√ÅLISIS DE COMPORTAMIENTO DE L:")
    print(f"   L inicial: {L_inicial:.3f}")
    print(f"   L final: {L_final:.3f}")
    print(f"   Cambio total: {L_cambio:.1f}%")
    
    # Buscar tendencias
    if L_cambio < -20:
        print("   üìâ TENDENCIA: L muestra deterioro significativo")
    elif L_cambio < -10:
        print("   üìä TENDENCIA: L muestra deterioro moderado")
    else:
        print("   ‚úÖ TENDENCIA: L se mantiene estable")
    
    # Verificar si L predijo problemas antes que val_loss
    val_loss_inicial = historial['loss_val'][0]
    val_loss_final = historial['loss_val'][-1]
    val_deterioro = ((val_loss_final - val_loss_inicial) / val_loss_inicial) * 100
    
    print(f"\nüîÆ COMPARACI√ìN L vs val_loss:")
    print(f"   L cambi√≥: {L_cambio:.1f}%")
    print(f"   val_loss cambi√≥: {val_deterioro:.1f}%")
    
    if deterioro_epoca is not None:
        print(f"   üí° L detect√≥ deterioro en √©poca {deterioro_epoca}")
        print(f"   Esto sugiere que L ES SENSIBLE a cambios en el modelo")
    
    # Estad√≠sticas finales
    regimen_counts = {}
    for regimen in historial['regimen']:
        regimen_counts[regimen] = regimen_counts.get(regimen, 0) + 1
    
    print(f"\nüìã DISTRIBUCI√ìN DE R√âGIMEN:")
    for regimen, count in regimen_counts.items():
        porcentaje = (count / len(historial['regimen'])) * 100
        print(f"   {regimen}: {count} √©pocas ({porcentaje:.1f}%)")
    
    # Generar gr√°ficos
    generar_graficos_extremos(historial)
    
    print(f"\nüíæ Gr√°ficos extremos guardados en: /workspace/sovereignty_extremo_final.png")
    print("="*70)
    
    # === CONCLUSI√ìN FINAL ===
    print("üèÅ CONCLUSI√ìN DEL EXPERIMENTO EXTREMO:")
    
    if colapso_epoca is not None:
        print("üéâ √âXITO PARCIAL: L detect√≥ colapso severo")
        print("   Esto confirma que L es sensible a deterioro extremo")
    elif deterioro_epoca is not None:
        print("üéØ √âXITO: L detect√≥ deterioro gradual")
        print("   L es sensible a cambios en el modelo antes que val_loss")
    elif abs(L_cambio) > 10:
        print("üìä RESULTADO: L mostr√≥ sensibilidad a cambios")
        print("   L responde a modificaciones del modelo")
    else:
        print("ü§î RESULTADO: L se mantuvo estable")
        print("   El modelo no colaps√≥ bajo estas condiciones extremas")
    
    print("\nüí° IMPLICACIONES PARA RESMA:")
    print("   ‚úì L es sensible a cambios en la estructura del modelo")
    print("   ‚úì L puede detectar deterioro gradual")
    print("   ‚úì Los umbrales podr√≠an necesitar calibraci√≥n por tipo de modelo")
    print("   ‚úì Se necesitan m√°s experimentos con diferentes arquitecturas")
    
    return historial

def generar_graficos_extremos(historial):
    """Genera gr√°ficos del experimento extremo"""
    setup_matplotlib_for_plotting()
    
    fig, axes = plt.subplots(3, 2, figsize=(16, 18))
    fig.suptitle('üíÄ SOVEREIGNTY MONITOR: Experimento de Colapso Extremo', 
                 fontsize=18, fontweight='bold')
    
    # Plot 1: P√©rdida
    axes[0,0].plot(historial['epoca'], historial['loss_train'], 'b-', linewidth=2, label='Train Loss')
    axes[0,0].plot(historial['epoca'], historial['loss_val'], 'r-', linewidth=2, label='Val Loss')
    axes[0,0].set_title('Evoluci√≥n de P√©rdida en Condiciones Extremas', fontweight='bold')
    axes[0,0].set_xlabel('√âpoca')
    axes[0,0].set_ylabel('Loss')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)
    
    # Plot 2: M√âTRICA L - LA CLAVE
    axes[0,1].plot(historial['epoca'], historial['L_promedio'], 'purple', linewidth=3, label='L Promedio')
    axes[0,1].axhline(y=1.0, color='green', linestyle='--', alpha=0.8, label='Umbral Soberano (1.0)')
    axes[0,1].axhline(y=0.5, color='orange', linestyle='--', alpha=0.8, label='Umbral Espurio (0.5)')
    axes[0,1].fill_between(historial['epoca'], 0, 0.5, alpha=0.3, color='red', label='Zona Espurio')
    axes[0,1].set_title('üíÄ M√âTRICA L: ¬øResisti√≥ el Colapso Extremo?', fontweight='bold')
    axes[0,1].set_xlabel('√âpoca')
    axes[0,1].set_ylabel('L (Libertad)')
    axes[0,1].legend()
    axes[0,1].grid(True, alpha=0.3)
    
    # Plot 3: L por capa - Detalle
    axes[1,0].plot(historial['epoca'], historial['L_fc1'], 'blue', linewidth=2, label='L FC1 (1024)')
    axes[1,0].plot(historial['epoca'], historial['L_fc2'], 'green', linewidth=2, label='L FC2 (512)')
    axes[1,0].plot(historial['epoca'], historial['L_fc3'], 'red', linewidth=2, label='L FC3 (256)')
    axes[1,0].plot(historial['epoca'], historial['L_fc4'], 'orange', linewidth=2, label='L FC4 (128)')
    axes[1,0].plot(historial['epoca'], historial['L_fc5'], 'purple', linewidth=2, label='L FC5 (10)')
    axes[1,0].axhline(y=0.5, color='black', linestyle='--', alpha=0.8, label='Umbral Espurio')
    axes[1,0].set_title('L por Capa Individual - An√°lisis Detallado')
    axes[1,0].set_xlabel('√âpoca')
    axes[1,0].set_ylabel('L')
    axes[1,0].legend()
    axes[1,0].grid(True, alpha=0.3)
    
    # Plot 4: Entrop√≠a de von Neumann
    axes[1,1].plot(historial['epoca'], historial['entropia'], 'orange', linewidth=2, label='Entrop√≠a vN')
    axes[1,1].set_title('Evoluci√≥n de Entrop√≠a de von Neumann')
    axes[1,1].set_xlabel('√âpoca')
    axes[1,1].set_ylabel('S_vN')
    axes[1,1].legend()
    axes[1,1].grid(True, alpha=0.3)
    
    # Plot 5: Correlaci√≥n L vs Val Loss
    colors = plt.cm.plasma(np.linspace(0, 1, len(historial['epoca'])))
    scatter = axes[2,0].scatter(historial['L_promedio'], historial['loss_val'], 
                              c=historial['epoca'], cmap='plasma', s=80, alpha=0.8)
    axes[2,0].set_xlabel('L Promedio')
    axes[2,0].set_ylabel('Val Loss')
    axes[2,0].set_title('Correlaci√≥n L vs Val Loss (color = √©poca)')
    axes[2,0].grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=axes[2,0], label='√âpoca')
    
    # Plot 6: Tendencia de L
    axes[2,1].plot(historial['epoca'], historial['L_promedio'], 'purple', linewidth=3, label='Tendencia de L')
    axes[2,1].axhline(y=historial['L_promedio'][0], color='blue', linestyle='--', alpha=0.7, label='L Inicial')
    axes[2,1].axhline(y=historial['L_promedio'][0] * 0.5, color='red', linestyle='--', alpha=0.7, label='50% del Inicial')
    axes[2,1].set_title('An√°lisis de Tendencia de L')
    axes[2,1].set_xlabel('√âpoca')
    axes[2,1].set_ylabel('L')
    axes[2,1].legend()
    axes[2,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('/workspace/sovereignty_extremo_final.png', dpi=300, bbox_inches='tight')
    plt.close()

if __name__ == "__main__":
    try:
        historial = experimento_colapso_forzado()
        print("\nüéâ EXPERIMENTO EXTREMO COMPLETADO")
        
        # Mostrar tabla resumen con L por capa
        print("\nüìã TABLA RESUMEN EXTREMA:")
        print("-"*80)
        print(f"{'Ep':<3} {'Train':<8} {'Val':<8} {'L_avg':<6} {'L_fc1':<6} {'L_fc2':<6} {'R√©gimen'}")
        print("-"*80)
        for i in range(len(historial['epoca'])):
            ep = historial['epoca'][i]
            train_loss = historial['loss_train'][i]
            val_loss = historial['loss_val'][i]
            L_avg = historial['L_promedio'][i]
            L_fc1 = historial['L_fc1'][i]
            L_fc2 = historial['L_fc2'][i]
            regimen = historial['regimen'][i]
            print(f"{ep:<3} {train_loss:<8.4f} {val_loss:<8.4f} {L_avg:<6.3f} {L_fc1:<6.3f} {L_fc2:<6.3f} {regimen}")
        print("-"*80)
        
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
